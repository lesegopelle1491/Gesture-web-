<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Hand Gesture Detection</title>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils"></script>
    <style>
        #videoInput {
            display: none; /* Hide the video element */
        }
        #outputCanvas {
            border: 1px solid black;
        }
    </style>
</head>
<body>
    <h1>Hand Gesture Recognition</h1>
    <video id="videoInput" autoplay playsinline></video> <!-- Hidden -->
    <canvas id="outputCanvas" width="640" height="480"></canvas> <!-- Visible -->
    <p id="gestureOutput" style="font-size: 20px; color: green;">Gesture: None</p>

    <script>
        const video = document.getElementById('videoInput');
        const canvas = document.getElementById('outputCanvas');
        const ctx = canvas.getContext('2d');
        const gestureOutput = document.getElementById('gestureOutput');

        // Initialize MediaPipe Hands
        const hands = new Hands({
            locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`,
        });

        hands.setOptions({
            maxNumHands: 2,
            minDetectionConfidence: 0.5,
            minTrackingConfidence: 0.5,
            modelComplexity: 1,
        });

        hands.onResults((results) => {
            // Clear the canvas
            ctx.clearRect(0, 0, canvas.width, canvas.height);

            // Draw the input video to the canvas
            ctx.drawImage(results.image, 0, 0, canvas.width, canvas.height);

            // Process landmarks if detected
            if (results.multiHandLandmarks && results.multiHandLandmarks.length > 0) {
                results.multiHandLandmarks.forEach((landmarks) => {
                    // Draw landmarks on canvas
                    drawLandmarks(landmarks);

                    // Detect and classify gesture
                    const gesture = detectGesture(landmarks);
                    gestureOutput.textContent = `Gesture: ${gesture}`;
                });
            } else {
                gestureOutput.textContent = "Gesture: None";
            }
        });

        // Function to draw landmarks
        function drawLandmarks(landmarks) {
            landmarks.forEach((point) => {
                const x = point.x * canvas.width;
                const y = point.y * canvas.height;

                ctx.beginPath();
                ctx.arc(x, y, 5, 0, 2 * Math.PI);
                ctx.fillStyle = "red";
                ctx.fill();
                ctx.closePath();
            });
        }

        // Function to detect and classify gestures
        function detectGesture(landmarks) {
            const [thumbTip, indexTip, middleTip, ringTip, pinkyTip] = [
                landmarks[4], landmarks[8], landmarks[12], landmarks[16], landmarks[20],
            ];

            const [thumbMCP, wrist] = [landmarks[2], landmarks[0]];

            // Basic gesture classification
            if (thumbTip.y < indexTip.y && middleTip.y > wrist.y) return "Thumb Up"; 
            if (thumbTip.y > wrist.y) return "Thumb Down";                         
            if (indexTip.y < thumbTip.y && middleTip.y > indexTip.y) return "Pointing Up";
            if (indexTip.y > thumbTip.y && pinkyTip.y > wrist.y) return "Closed Fist";
            if (thumbTip.x > pinkyTip.x && indexTip.y < wrist.y) return "Victory";  
            if (thumbTip.y < wrist.y && pinkyTip.y < wrist.y) return "Open Palm";  
            if (thumbTip.y < wrist.y && pinkyTip.x < wrist.x) return "Love";

            return "Unrecognized Gesture";
        }

        // Initialize camera
        const camera = new Camera(video, {
            onFrame: async () => {
                await hands.send({image: video});
            },
            width: 640,
            height: 480,
        });
        camera.start();
    </script>
</body>
</html>
<link href="https://unpkg.com/material-components-web@latest/dist/material-components-web.min.css" rel="stylesheet">
<script src="https://unpkg.com/material-components-web@latest/dist/material-components-web.min.js"></script>

<h1>Recognize hand gestures using the MediaPipe HandGestureRecognizer task</h1>

<section id="demos" class="invisible">
  <h2>Demo: Recognize gestures</h2>
  <p><em>Click on an image below</em> to identify the gestures in the image.</p>

  <div class="detectOnClick">
    <img src="https://assets.codepen.io/9177687/idea-gcbe74dc69_1920.jpg" crossorigin="anonymous" title="Click to get recognize!" />
    <p class="classification removed">
  </div>
  <div class="detectOnClick">
    <img src="https://assets.codepen.io/9177687/thumbs-up-ga409ddbd6_1.png" crossorigin="anonymous" title="Click to get recognize!" />
    <p class="classification removed">
  </div>

  <h2><br>Demo: Webcam continuous hand gesture detection</h2>
  <p>Use your hand to make gestures in front of the camera to get gesture classification. </br>Click <b>enable webcam</b> below and grant access to the webcam if prompted.</p>

  <div id="liveView" class="videoView">
    <button id="webcamButton" class="mdc-button mdc-button--raised">
      <span class="mdc-button__ripple"></span>
      <span class="mdc-button__label">ENABLE WEBCAM</span>
    </button>
    <div style="position: relative;">
      <video id="webcam" autoplay playsinline></video>
      <canvas class="output_canvas" id="output_canvas" width="1280" height="720" style="position: absolute; left: 0px; top: 0px;"></canvas>
      <p id='gesture_output' class="output">
    </div>
  </div>
</section>


Resources